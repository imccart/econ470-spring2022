---
title: "Homework 1"
linktitle: "Homework 1"
due_date: "2021-02-25"
due_time: "11:59 PM"
output:
  blogdown::html_page:
    toc: false
menu:
  assignment:
    parent: Homework
    weight: 1
type: docs
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Instructions
This assignment is just about GitHub and data management. The goal is to give you a chance to practice wrangling and tidying data. We do this very early in the class because soon (**next week**) we will start doing some empirical analysis using real data. The sooner you are comfortable with the datasets, the better.

Please turn in your empirical work as an `R Markdown` document. If you are not familiar with `R Markdown`, take a look at the following resources:

- [R Markdown: The Definitive Guide](https://bookdown.org/yihui/rmarkdown/)
- [Using R Markdown for Class Reports](https://www.stat.cmu.edu/~cshalizi/rmarkdown/)

If you're still new to `R Markdown`, then there will be some growing pains. Please be patient with yourself and stick to it. One of the goals of the course is to develop good workflow habits. This means doing work in a way that minimizes mistakes and maximizes reproducability. `R Markdown` exists exactly for these reasons. It allows you to keep your data analysis and the description of that analysis together in a single document or group of documents. It's really easy to introduce mistakes when copying and pasting empirical results into a text document, and it's even easier to waste hours (*days/weeks?*) re-pasting results into your text document and re-writing the results accordingly. Doing everything in `R Markdown` avoids all of these issues. In the long run, it's much more efficient.

You can submit your answers as an html document in your personal GitHub repo. You will receive an invitation to each assignment through GitHub Classroom, which will automatically link to your personal repository for each assignment. From there, you just need to develop the code files as needed. Please include all of your final answers as part of the ReadMe file. Practice writing good code and showing me only what I would need to recreate your results.


# Using *Git* and *GitHub*
The first part of the assignment is to confirm you're good with *Git* and *GitHub*. 

1. Log in to [LinkedIn Learning](https://www.linkedin.com/learning/). It's free if you sign in through Emory, then you can link to your personal LinkedIn account. 

2. Take the [Learning GitHub](https://www.linkedin.com/learning/learning-github?u=2149178) course. It takes a couple of hours to complete. Once it's completed, you'll get a certificate added to your LinkedIn profile. 

3. Add your certificate to your answers in `R Markdown`. Hint: to add an image in the document, you can do something like: `![](D:/pictures/screenshot.png)`


# Building the data
Now let's do some data work. The purpose of this part of the assignment is essentially to practice database management. Most of your professional lives will likely involve managing data. It can be tedious but also extremely rewarding when you finally get to find out what's going on in the analysis stage. Anyway, let's get to work! All of these questions require you to use the [Medicare Advantage GitHub Repo](https://github.com/imccart/Medicare-Advantage).


## Enrollment Data
Run the `R` code to organize the [Monthly Plan Enrollment Data](https://github.com/imccart/Medicare-Advantage/blob/master/R_code/1_Plan_Data.R). Once you've created your final dataset (it's called *full_ma_data* in my code), answer the following:

1. How many observations exist in your current dataset? 

2. How many different *plan_types* exist in the data?

3. Provide a table of the count of plans under each plan type in each year. Your table should look something like Table \@ref(tab:plancount).

```{r, include=F}
test.data <- matrix(round(runif(15,10,50),0),nrow=3, ncol=6)
row.names(test.data) <- c("Type 1", "Type 2", "Type 3")
```

```{r plancount, include=T, eval=T}
knitr::kable(test.data, col.names=c("2010","2011","2012","2013","2014","2015"),
             type="html", caption = "Plan Count by Year", booktabs = TRUE)
```

4. Remove all special needs plans (SNP), employer group plans (eghp), and all "800-series" plans. Provide an updated version of Table \@ref(tab:plancount) after making these exclusions.

5. Merge the the contract service area data to the enrollment data and restrict the data only to contracts that are approved in their respective counties. The `R` script to create the service area dataset is here: [Contract Service Area](https://github.com/imccart/Medicare-Advantage/blob/master/R_code/1_Plan_Data.R). And you can follow the [[_BuildFinalData.r](https://github.com/imccart/Medicare-Advantage/blob/master/R_code/_BuildFinalData.R) script to see where/how I join the datasets. The join takes place in the following section of the code:

```{r, eval=F, echo=T}
final.data <- full.ma.data %>%
  inner_join(contract.service.area %>% 
               select(contractid, fips, year), 
             by=c("contractid", "fips", "year")) %>%
  filter(!state %in% c("VI","PR","MP","GU","AS","") &
           snp == "No" &
           (planid < 800 | planid >= 900) &
           !is.na(planid) & !is.na(fips))
```

6. Finally, limit your dataset only to plans with non-missing enrollment data. Provide a graph showing the average number of Medicare Advantage enrollees per county from 2008 to 2015. Be sure to format your graph in a meaningful way as we did in class.

## Premium Data
Now we're going to incorporate the plan premium information. This is part of the "Plan Characteristics" data, and the underlying R scripts for these files can be found here: [Plan Characteristics](https://github.com/imccart/Medicare-Advantage/blob/master/R_code/2_Plan_Characteristics.R).

1. Merge the plan characteristics data to the dataset you created in Step 6 above. Note that you'll need to join the [Market Penetration Data](https://github.com/imccart/Medicare-Advantage/blob/master/R_code/4_Penetration_Files.R) in order to get the information you need to merge the plan characteristics. This is because the plan characteristics data only have state name and county (not FIPS codes). The penetration files have both FIPS codes and state/county names, so that dataset serves as a good crosswalk file.

2. Provide a graph showing the average premium over time. Don't forget about formatting!

3. Provide a graph showing the percentage of $0 premium plans over time. Also...remember to format things.

# Summary Questions
With all of this data work and these great summaries, let's take a step back and think about what all this means.

1. Why did we drop the "800-series" plans?

2. Why do so many plans charge a $0 premium? What does that really mean to a beneficiary?

3. Briefly describe your experience working with these data (just a few sentences). Tell me one thing you learned and one thing that really aggravated you.
